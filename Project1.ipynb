{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traffic Sign Identification using Deep Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "Lorem Ipsum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Image Preprocessing\n",
    "\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pickle\n",
    "import csv\n",
    "from skimage import exposure\n",
    "\n",
    "#A tua mina, tem ganda vagina\n",
    "#Mas nÃ£o foste tu quem escavou bro, foi o Chico da Tina"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Function\n",
    "Resizes and Normalizes all pictures in all of our datasets and then stores them in a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_images(file_name):\n",
    "    path = './Dataset/'   # Change this for the path corresponding to your base Dataset directory\n",
    "\n",
    "    img_infos = {'labels':[],'images':[]}\n",
    "\n",
    "    with open(path+file_name,\"r\") as csv_file:\n",
    "        reader = csv.reader(csv_file, delimiter=',', quotechar='|')\n",
    "        next(reader)\n",
    "        \n",
    "        for row in reader:\n",
    "\n",
    "            img = cv2.imread(path+row[-1], cv2.IMREAD_UNCHANGED)    \n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) #Convert image to Grayscale\n",
    "            \n",
    "            img = cv2.resize(img, (32,32),interpolation = cv2.INTER_AREA) #Resize the image to 32x32\n",
    "\n",
    "            #img = cv2.addWeighted( img, 1.2, img, 0, 0) #Increase contrast\n",
    "            \n",
    "            cv2.normalize(img, img, 0, 255, cv2.NORM_MINMAX) #Normalize\n",
    "            \n",
    "            img_eq = exposure.equalize_adapthist(img, clip_limit=0.03)\n",
    "            \n",
    "            img_infos['images'].append(img_eq) #Save Image pixels\n",
    "            img_infos['labels'].append(row[-2]) #Save image Label\n",
    "            \n",
    "    return img_infos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save treated data as Pickle\n",
    "Srsly, funniest thing I've ever seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished writing tests\n",
      "finished writing train\n"
     ]
    }
   ],
   "source": [
    "img_infos = preprocess_images(\"Test.csv\")\n",
    "with open(\"./Dataset/PickledData/Test.p\", 'wb') as pickle_rick:\n",
    "    pickle.dump(img_infos,pickle_rick)\n",
    "    \n",
    "print(\"> Finished writing tests\")\n",
    "img_infos = preprocess_images(\"Train.csv\")\n",
    "with open(\"./Dataset/PickledData/Train.p\", 'wb') as pickle_rick:\n",
    "    pickle.dump(img_infos,pickle_rick)\n",
    "print(\"> Finished writing train\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network\n",
    "\n",
    "### Step 0 - Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.protobuf'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-5dad6ed9ae91>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# pylint: disable=g-bad-import-order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m  \u001b[0;31m# pylint: disable=unused-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodule_util\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_module_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;31m# Protocol buffers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_pb2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_def_pb2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary_pb2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/core/framework/graph_pb2.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0m_b\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;36m3\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'latin1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotobuf\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdescriptor\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_descriptor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotobuf\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmessage\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotobuf\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mreflection\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_reflection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.protobuf'"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 - Get the data into the sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./Dataset/PickledData/Test.p\", \"rb\") as f:\n",
    "    test = pickle.load(f)\n",
    "with open(\"./Dataset/PickledData/Train.p\", \"rb\") as f:\n",
    "    train = pickle.load(f)\n",
    "\n",
    "# Get the training set\n",
    "x_train, y_train = train['images'], train['labels']\n",
    "\n",
    "# Get the cross validation set\n",
    "x_cv = []\n",
    "y_cv = []\n",
    "for i in range(int(0.2*len(x_train))): # Randomly move 20% of the training examples into the cross-validation set\n",
    "    index = random.randint(0, len(x_train)-1)\n",
    "    x_cv.append(x_train.pop(index))\n",
    "    y_cv.append(y_train.pop(index))\n",
    "    \n",
    "# Get the test set\n",
    "x_test, y_test = test['images'], test['labels']\n",
    "\n",
    "# Convert all our sets into numPy Arrays\n",
    "x_train = np.array(x_train).reshape((len(x_train), 32, 32, 1))\n",
    "y_train = keras.utils.to_categorical(np.array(y_train))\n",
    "\n",
    "x_cv = np.array(x_cv).reshape((len(x_cv), 32, 32, 1))\n",
    "y_cv = keras.utils.to_categorical(np.array(y_cv))\n",
    "\n",
    "x_test = np.array(x_test).reshape((len(x_test), 32, 32, 1))\n",
    "y_test = keras.utils.to_categorical(np.array(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 - Treat the data (Normalize and Shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the training set\n",
    "x_train, y_train = shuffle(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 - Define constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "BATCH_SIZE = 200\n",
    "\n",
    "LEARNING_RATE = 0.002 # Define the learning rate to be used by our optimizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4 - Define the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LeNetModel(no_output=6, rgb=True, dropout=0):\n",
    "    input_shape = (32,32,3) if rgb else (32,32,1) # Define the image's size\n",
    "    \n",
    "    model = keras.Sequential() # Define the Keras Model\n",
    "    \n",
    "    # First Layer - Convolutional ; Input = 32x32x3 for RGB , 32x32x1 for GrayScale ; Output = 28x28x6\n",
    "    model.add(keras.layers.Conv2D(\n",
    "                filters=no_output, kernel_size=(3, 3),\n",
    "                activation='relu', input_shape=input_shape\n",
    "                )\n",
    "             )\n",
    "    \n",
    "    # Second Layer - Subsampling (Average Pooling) ; Input = 28x28x6 ; Output = 14x14x6\n",
    "    model.add(keras.layers.AveragePooling2D())\n",
    "    \n",
    "    # Third Layer - Convolutional ; Input = 14x14x6 ; Output = 10x10x16\n",
    "    model.add(keras.layers.Conv2D(\n",
    "                    filters=16, kernel_size=(3, 3),\n",
    "                    activation='relu'\n",
    "                    )\n",
    "                 )\n",
    "    \n",
    "    # Fourth Layer - Subsampling (Average Pooling) ; Input = 10x10x16 ; Output = 5x5x16\n",
    "    model.add(keras.layers.AveragePooling2D())\n",
    "    \n",
    "    model.add(keras.layers.Flatten()) # Flatten the last layer's output to pass it to the Fully Connected layers\n",
    "    \n",
    "    # Fifth Layer - Fully Connected ; Input = 5x5x16 ; Output = 120x1\n",
    "    model.add(keras.layers.Dense(units=120, activation='relu'))\n",
    "\n",
    "    # Sixth Layer - Fully Connected ; Input = 120x1 ; Output = 84x1\n",
    "    model.add(keras.layers.Dense(units=84, activation='relu'))\n",
    "    \n",
    "    model.add(keras.layers.Dropout(dropout))\n",
    "    \n",
    "    # Output Layer - Output = 43x1\n",
    "    model.add(keras.layers.Dense(units=43, activation = 'softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5 - Create the model and define evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LeNetModel(rgb=False, dropout=0.50)\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "              metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6 - Insert the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 31368 samples, validate on 7841 samples\n",
      "Epoch 1/50\n",
      "31368/31368 [==============================] - 5s 164us/sample - loss: 2.5409 - accuracy: 0.3054 - precision_1: 0.8058 - recall_1: 0.1336 - val_loss: 1.1143 - val_accuracy: 0.6736 - val_precision_1: 0.9018 - val_recall_1: 0.4286\n",
      "Epoch 2/50\n",
      "31368/31368 [==============================] - 4s 135us/sample - loss: 1.0547 - accuracy: 0.6658 - precision_1: 0.8444 - recall_1: 0.5149 - val_loss: 0.6046 - val_accuracy: 0.8186 - val_precision_1: 0.9124 - val_recall_1: 0.7224\n",
      "Epoch 3/50\n",
      "31368/31368 [==============================] - 4s 135us/sample - loss: 0.7001 - accuracy: 0.7744 - precision_1: 0.8731 - recall_1: 0.6806 - val_loss: 0.4035 - val_accuracy: 0.8865 - val_precision_1: 0.9304 - val_recall_1: 0.8373\n",
      "Epoch 4/50\n",
      "31368/31368 [==============================] - 4s 133us/sample - loss: 0.5350 - accuracy: 0.8287 - precision_1: 0.8938 - recall_1: 0.7657 - val_loss: 0.3144 - val_accuracy: 0.9056 - val_precision_1: 0.9378 - val_recall_1: 0.8781\n",
      "Epoch 5/50\n",
      "31368/31368 [==============================] - 4s 136us/sample - loss: 0.4224 - accuracy: 0.8648 - precision_1: 0.9108 - recall_1: 0.8201 - val_loss: 0.2588 - val_accuracy: 0.9217 - val_precision_1: 0.9456 - val_recall_1: 0.8996\n",
      "Epoch 6/50\n",
      "31368/31368 [==============================] - 4s 139us/sample - loss: 0.3670 - accuracy: 0.8830 - precision_1: 0.9214 - recall_1: 0.8472 - val_loss: 0.2180 - val_accuracy: 0.9342 - val_precision_1: 0.9543 - val_recall_1: 0.9190\n",
      "Epoch 7/50\n",
      "31368/31368 [==============================] - 4s 133us/sample - loss: 0.3153 - accuracy: 0.8994 - precision_1: 0.9308 - recall_1: 0.8716 - val_loss: 0.1884 - val_accuracy: 0.9453 - val_precision_1: 0.9625 - val_recall_1: 0.9320\n",
      "Epoch 8/50\n",
      "31368/31368 [==============================] - 4s 128us/sample - loss: 0.2672 - accuracy: 0.9142 - precision_1: 0.9386 - recall_1: 0.8916 - val_loss: 0.1627 - val_accuracy: 0.9532 - val_precision_1: 0.9666 - val_recall_1: 0.9438\n",
      "Epoch 9/50\n",
      "31368/31368 [==============================] - 4s 127us/sample - loss: 0.2329 - accuracy: 0.9277 - precision_1: 0.9479 - recall_1: 0.9088 - val_loss: 0.1510 - val_accuracy: 0.9538 - val_precision_1: 0.9650 - val_recall_1: 0.9454\n",
      "Epoch 10/50\n",
      "31368/31368 [==============================] - 4s 141us/sample - loss: 0.2117 - accuracy: 0.9324 - precision_1: 0.9501 - recall_1: 0.9164 - val_loss: 0.1434 - val_accuracy: 0.9588 - val_precision_1: 0.9688 - val_recall_1: 0.9531\n",
      "Epoch 11/50\n",
      "31368/31368 [==============================] - 4s 133us/sample - loss: 0.1853 - accuracy: 0.9412 - precision_1: 0.9561 - recall_1: 0.9280 - val_loss: 0.1190 - val_accuracy: 0.9670 - val_precision_1: 0.9754 - val_recall_1: 0.9607\n",
      "Epoch 12/50\n",
      "31368/31368 [==============================] - 4s 136us/sample - loss: 0.1664 - accuracy: 0.9467 - precision_1: 0.9599 - recall_1: 0.9359 - val_loss: 0.1168 - val_accuracy: 0.9665 - val_precision_1: 0.9751 - val_recall_1: 0.9621\n",
      "Epoch 13/50\n",
      "31368/31368 [==============================] - 4s 136us/sample - loss: 0.1540 - accuracy: 0.9512 - precision_1: 0.9636 - recall_1: 0.9410 - val_loss: 0.1189 - val_accuracy: 0.9657 - val_precision_1: 0.9709 - val_recall_1: 0.9624\n",
      "Epoch 14/50\n",
      "31368/31368 [==============================] - 4s 112us/sample - loss: 0.1406 - accuracy: 0.9548 - precision_1: 0.9654 - recall_1: 0.9465 - val_loss: 0.1098 - val_accuracy: 0.9679 - val_precision_1: 0.9751 - val_recall_1: 0.9645\n",
      "Epoch 15/50\n",
      "31368/31368 [==============================] - 3s 104us/sample - loss: 0.1261 - accuracy: 0.9585 - precision_1: 0.9673 - recall_1: 0.9504 - val_loss: 0.0931 - val_accuracy: 0.9726 - val_precision_1: 0.9790 - val_recall_1: 0.9705\n",
      "Epoch 16/50\n",
      "31368/31368 [==============================] - 3s 107us/sample - loss: 0.1196 - accuracy: 0.9612 - precision_1: 0.9695 - recall_1: 0.9543 - val_loss: 0.0896 - val_accuracy: 0.9759 - val_precision_1: 0.9805 - val_recall_1: 0.9737\n",
      "Epoch 17/50\n",
      "31368/31368 [==============================] - 3s 102us/sample - loss: 0.1098 - accuracy: 0.9641 - precision_1: 0.9718 - recall_1: 0.9577 - val_loss: 0.0930 - val_accuracy: 0.9716 - val_precision_1: 0.9765 - val_recall_1: 0.9679\n",
      "Epoch 18/50\n",
      "31368/31368 [==============================] - 3s 103us/sample - loss: 0.1016 - accuracy: 0.9674 - precision_1: 0.9747 - recall_1: 0.9615 - val_loss: 0.0897 - val_accuracy: 0.9758 - val_precision_1: 0.9797 - val_recall_1: 0.9739\n",
      "Epoch 19/50\n",
      "31368/31368 [==============================] - 3s 104us/sample - loss: 0.0896 - accuracy: 0.9700 - precision_1: 0.9765 - recall_1: 0.9648 - val_loss: 0.0795 - val_accuracy: 0.9776 - val_precision_1: 0.9816 - val_recall_1: 0.9751\n",
      "Epoch 20/50\n",
      "31368/31368 [==============================] - 3s 103us/sample - loss: 0.0818 - accuracy: 0.9726 - precision_1: 0.9787 - recall_1: 0.9685 - val_loss: 0.0830 - val_accuracy: 0.9784 - val_precision_1: 0.9812 - val_recall_1: 0.9760\n",
      "Epoch 21/50\n",
      "31368/31368 [==============================] - 3s 103us/sample - loss: 0.0801 - accuracy: 0.9726 - precision_1: 0.9784 - recall_1: 0.9687 - val_loss: 0.0800 - val_accuracy: 0.9786 - val_precision_1: 0.9820 - val_recall_1: 0.9767\n",
      "Epoch 22/50\n",
      "31368/31368 [==============================] - 3s 107us/sample - loss: 0.0730 - accuracy: 0.9765 - precision_1: 0.9808 - recall_1: 0.9733 - val_loss: 0.0730 - val_accuracy: 0.9811 - val_precision_1: 0.9837 - val_recall_1: 0.9795\n",
      "Epoch 23/50\n",
      "31368/31368 [==============================] - 3s 105us/sample - loss: 0.0641 - accuracy: 0.9792 - precision_1: 0.9831 - recall_1: 0.9758 - val_loss: 0.0781 - val_accuracy: 0.9801 - val_precision_1: 0.9830 - val_recall_1: 0.9787\n",
      "Epoch 24/50\n",
      "31368/31368 [==============================] - 3s 104us/sample - loss: 0.0668 - accuracy: 0.9773 - precision_1: 0.9814 - recall_1: 0.9742 - val_loss: 0.0685 - val_accuracy: 0.9814 - val_precision_1: 0.9846 - val_recall_1: 0.9804\n",
      "Epoch 25/50\n",
      "31368/31368 [==============================] - 3s 109us/sample - loss: 0.0596 - accuracy: 0.9800 - precision_1: 0.9838 - recall_1: 0.9772 - val_loss: 0.0678 - val_accuracy: 0.9834 - val_precision_1: 0.9857 - val_recall_1: 0.9818\n",
      "Epoch 26/50\n",
      "31368/31368 [==============================] - 3s 111us/sample - loss: 0.0553 - accuracy: 0.9819 - precision_1: 0.9843 - recall_1: 0.9794 - val_loss: 0.0796 - val_accuracy: 0.9814 - val_precision_1: 0.9841 - val_recall_1: 0.9801\n",
      "Epoch 27/50\n",
      "31368/31368 [==============================] - 3s 109us/sample - loss: 0.0575 - accuracy: 0.9811 - precision_1: 0.9838 - recall_1: 0.9784 - val_loss: 0.0680 - val_accuracy: 0.9824 - val_precision_1: 0.9851 - val_recall_1: 0.9813\n",
      "Epoch 28/50\n",
      "31368/31368 [==============================] - 3s 106us/sample - loss: 0.0486 - accuracy: 0.9834 - precision_1: 0.9859 - recall_1: 0.9808 - val_loss: 0.0723 - val_accuracy: 0.9823 - val_precision_1: 0.9835 - val_recall_1: 0.9813\n",
      "Epoch 29/50\n",
      "31368/31368 [==============================] - 4s 115us/sample - loss: 0.0485 - accuracy: 0.9838 - precision_1: 0.9864 - recall_1: 0.9815 - val_loss: 0.0662 - val_accuracy: 0.9835 - val_precision_1: 0.9854 - val_recall_1: 0.9823\n",
      "Epoch 30/50\n",
      "31368/31368 [==============================] - 3s 109us/sample - loss: 0.0481 - accuracy: 0.9835 - precision_1: 0.9859 - recall_1: 0.9815 - val_loss: 0.0686 - val_accuracy: 0.9821 - val_precision_1: 0.9851 - val_recall_1: 0.9811\n",
      "Epoch 31/50\n",
      "31368/31368 [==============================] - 3s 107us/sample - loss: 0.0423 - accuracy: 0.9857 - precision_1: 0.9879 - recall_1: 0.9841 - val_loss: 0.0668 - val_accuracy: 0.9833 - val_precision_1: 0.9845 - val_recall_1: 0.9824\n",
      "Epoch 32/50\n",
      "31368/31368 [==============================] - 3s 109us/sample - loss: 0.0438 - accuracy: 0.9846 - precision_1: 0.9868 - recall_1: 0.9828 - val_loss: 0.0814 - val_accuracy: 0.9804 - val_precision_1: 0.9824 - val_recall_1: 0.9797\n",
      "Epoch 33/50\n",
      "31368/31368 [==============================] - 4s 133us/sample - loss: 0.0415 - accuracy: 0.9858 - precision_1: 0.9875 - recall_1: 0.9836 - val_loss: 0.0757 - val_accuracy: 0.9816 - val_precision_1: 0.9840 - val_recall_1: 0.9811\n",
      "Epoch 34/50\n",
      "31368/31368 [==============================] - 4s 135us/sample - loss: 0.0383 - accuracy: 0.9874 - precision_1: 0.9892 - recall_1: 0.9856 - val_loss: 0.0614 - val_accuracy: 0.9860 - val_precision_1: 0.9881 - val_recall_1: 0.9857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/50\n",
      "31368/31368 [==============================] - 4s 134us/sample - loss: 0.0369 - accuracy: 0.9873 - precision_1: 0.9897 - recall_1: 0.9858 - val_loss: 0.0668 - val_accuracy: 0.9865 - val_precision_1: 0.9875 - val_recall_1: 0.9860\n",
      "Epoch 36/50\n",
      "31368/31368 [==============================] - 4s 133us/sample - loss: 0.0329 - accuracy: 0.9886 - precision_1: 0.9899 - recall_1: 0.9873 - val_loss: 0.0698 - val_accuracy: 0.9844 - val_precision_1: 0.9857 - val_recall_1: 0.9842\n",
      "Epoch 37/50\n",
      "31368/31368 [==============================] - 4s 134us/sample - loss: 0.0402 - accuracy: 0.9859 - precision_1: 0.9877 - recall_1: 0.9841 - val_loss: 0.0677 - val_accuracy: 0.9843 - val_precision_1: 0.9861 - val_recall_1: 0.9837\n",
      "Epoch 38/50\n",
      "31368/31368 [==============================] - 4s 127us/sample - loss: 0.0329 - accuracy: 0.9881 - precision_1: 0.9897 - recall_1: 0.9865 - val_loss: 0.0714 - val_accuracy: 0.9838 - val_precision_1: 0.9848 - val_recall_1: 0.9834\n",
      "Epoch 39/50\n",
      "31368/31368 [==============================] - 4s 134us/sample - loss: 0.0329 - accuracy: 0.9889 - precision_1: 0.9901 - recall_1: 0.9877 - val_loss: 0.0715 - val_accuracy: 0.9864 - val_precision_1: 0.9869 - val_recall_1: 0.9858\n",
      "Epoch 40/50\n",
      "31368/31368 [==============================] - 4s 133us/sample - loss: 0.0352 - accuracy: 0.9877 - precision_1: 0.9891 - recall_1: 0.9866 - val_loss: 0.0689 - val_accuracy: 0.9865 - val_precision_1: 0.9879 - val_recall_1: 0.9860\n",
      "Epoch 41/50\n",
      "31368/31368 [==============================] - 4s 133us/sample - loss: 0.0302 - accuracy: 0.9896 - precision_1: 0.9908 - recall_1: 0.9883 - val_loss: 0.0620 - val_accuracy: 0.9841 - val_precision_1: 0.9861 - val_recall_1: 0.9839\n",
      "Epoch 42/50\n",
      "31368/31368 [==============================] - 4s 136us/sample - loss: 0.0255 - accuracy: 0.9916 - precision_1: 0.9924 - recall_1: 0.9909 - val_loss: 0.0757 - val_accuracy: 0.9848 - val_precision_1: 0.9857 - val_recall_1: 0.9844\n",
      "Epoch 43/50\n",
      "31368/31368 [==============================] - 4s 135us/sample - loss: 0.0286 - accuracy: 0.9903 - precision_1: 0.9913 - recall_1: 0.9893 - val_loss: 0.0685 - val_accuracy: 0.9862 - val_precision_1: 0.9879 - val_recall_1: 0.9857\n",
      "Epoch 44/50\n",
      "31368/31368 [==============================] - 4s 134us/sample - loss: 0.0241 - accuracy: 0.9916 - precision_1: 0.9927 - recall_1: 0.9908 - val_loss: 0.0728 - val_accuracy: 0.9848 - val_precision_1: 0.9857 - val_recall_1: 0.9847\n",
      "Epoch 45/50\n",
      "31368/31368 [==============================] - 5s 146us/sample - loss: 0.0246 - accuracy: 0.9916 - precision_1: 0.9926 - recall_1: 0.9910 - val_loss: 0.0683 - val_accuracy: 0.9865 - val_precision_1: 0.9872 - val_recall_1: 0.9856\n",
      "Epoch 46/50\n",
      "31368/31368 [==============================] - 5s 147us/sample - loss: 0.0256 - accuracy: 0.9918 - precision_1: 0.9928 - recall_1: 0.9910 - val_loss: 0.0727 - val_accuracy: 0.9846 - val_precision_1: 0.9856 - val_recall_1: 0.9839\n",
      "Epoch 47/50\n",
      "31368/31368 [==============================] - 5s 147us/sample - loss: 0.0244 - accuracy: 0.9919 - precision_1: 0.9927 - recall_1: 0.9910 - val_loss: 0.0712 - val_accuracy: 0.9864 - val_precision_1: 0.9872 - val_recall_1: 0.9861\n",
      "Epoch 48/50\n",
      "31368/31368 [==============================] - 4s 136us/sample - loss: 0.0214 - accuracy: 0.9928 - precision_1: 0.9934 - recall_1: 0.9919 - val_loss: 0.0713 - val_accuracy: 0.9869 - val_precision_1: 0.9876 - val_recall_1: 0.9862\n",
      "Epoch 49/50\n",
      "31368/31368 [==============================] - 4s 137us/sample - loss: 0.0228 - accuracy: 0.9922 - precision_1: 0.9929 - recall_1: 0.9914 - val_loss: 0.0824 - val_accuracy: 0.9846 - val_precision_1: 0.9862 - val_recall_1: 0.9842\n",
      "Epoch 50/50\n",
      "31368/31368 [==============================] - 4s 136us/sample - loss: 0.0231 - accuracy: 0.9926 - precision_1: 0.9932 - recall_1: 0.9917 - val_loss: 0.0738 - val_accuracy: 0.9865 - val_precision_1: 0.9871 - val_recall_1: 0.9865\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb8bfe656d0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          batch_size=BATCH_SIZE,\n",
    "          epochs=EPOCHS,\n",
    "          verbose=1,\n",
    "          validation_data=(x_cv, y_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12630/12630 [==============================] - 1s 97us/sample - loss: 0.3738 - accuracy: 0.9451 - precision_1: 0.9485 - recall_1: 0.9444\n",
      "Test loss: 0.37375960503714295\n",
      "Test accuracy: 0.9450515\n",
      "Test precision: 0.94854873\n",
      "Test recall: 0.9444181\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "print('Test precision:', score[2])\n",
    "print('Test recall:', score[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion of Results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RGB vs Grayscale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Epoch Numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Preprocessing Parameter changes (Contrast, lighting, etc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
